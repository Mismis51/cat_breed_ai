{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DaisyAI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqpGFeRsUixH"
      },
      "source": [
        "!unzip cat_dataset.zip\n",
        "!unzip image_test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-tdUJhLVP8T",
        "outputId": "ba70a1aa-a636-4db5-e580-603c750b60a6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May  3 08:25:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P0    71W / 149W |    126MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkDdqcukQz42"
      },
      "source": [
        "from DaisyModule import *\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "import PIL\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GyexWvHIRT3H",
        "outputId": "a35a0eb4-8f91-41c1-adab-ab2859366484"
      },
      "source": [
        "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
        "\n",
        "# Optimisation, décommenter les lignes suivantes si on utilise un GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "tf.test.gpu_device_name()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwoEvSD4RXkF"
      },
      "source": [
        "#Définir les paramètres\n",
        "cat_dataset = \"./Cat_Dataset\"\n",
        "save_directory = \"./Caches\"\n",
        "#Nombre d'images chargées dans le dataset à la fois. Garder ce nombre entre 16 et 64 si possible\n",
        "batch_size = 32\n",
        "image_height = 160\n",
        "image_width = 160\n",
        "#Taux d'apprentissage. Il est conseillé de le laisser à cette valeur pour éviter l'overfitting. On le changera plus tard\n",
        "base_learning_rate = 0.0001\n",
        "# Le nombre de fois the l'algorithme d'apprentissage va travailler à travers le dataset au complet. Mettre une valeur raisonnable, pour éviter l'overfitting\n",
        "epochs = 40\n",
        "# Le nombre de couches inférieures à garder bloquer. Le laisser à 100 avec MobilenetV2, et environ à 5 avec son modèle à soi, dépendamment de son nombre de couches.\n",
        "layer = 100\n",
        "num_classes = len(glob(cat_dataset + \"/*\"))\n",
        "class_names = sorted([i.replace(cat_dataset, \"\") for i in glob(cat_dataset+\"/*\")])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqdtnjMpUgLu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lzRLPlyRcrb",
        "outputId": "f4fd2562-b943-4b87-966c-bd4837a1d7b3"
      },
      "source": [
        "# Création des datasets. Définit les paramètres, puis créée les datasets individuellement\n",
        "dataset_parameters = make_dataset(cat_dataset, batch_size, image_height, image_width)\n",
        "train_dataset = dataset_parameters.train()\n",
        "validation_dataset = dataset_parameters.val()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2400 files belonging to 12 classes.\n",
            "Using 1920 files for training.\n",
            "Found 2400 files belonging to 12 classes.\n",
            "Using 480 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj28_B6hRd2f",
        "outputId": "f97f55d4-9cd3-45a1-ea0a-94941792b0ab"
      },
      "source": [
        "#Création du modèle. Ici on utilise MobileNetV2, mais on peut le changer pour son propre dataset\n",
        "model, base_model = make_model(image_height, image_width, train_dataset, num_classes).load_v2(base_learning_rate)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 160, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf.math.truediv (TFOpLambda) (None, 160, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf.math.subtract (TFOpLambda (None, 160, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_160 (Functi (None, 5, 5, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 12)                15372     \n",
            "=================================================================\n",
            "Total params: 2,273,356\n",
            "Trainable params: 15,372\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pfPTUS7RfdH",
        "outputId": "8359e180-4cbf-43a5-ee8a-9b098200a6a8"
      },
      "source": [
        "#Entraînement du modèle. Si la précision d'entraînement est supérieure à la précision de validation, ça veut dire que le modèle a commencé à mémoriser \n",
        "#les images du dataset par coeur, et n'est donc pas capable de généraliser. On appelle ça du overfitting.\n",
        "#Les solutions possibles sont, entre autres, augmenter le nombre d'images dans le dataset (et non pas la batch_size), et utiliser MobileNetV2, si ce n'est pas déjà fait.\n",
        "model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)\n",
        "model.evaluate(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "60/60 [==============================] - 42s 100ms/step - loss: 2.7342 - accuracy: 0.1301 - val_loss: 2.1910 - val_accuracy: 0.2479\n",
            "Epoch 2/40\n",
            "60/60 [==============================] - 10s 83ms/step - loss: 2.1617 - accuracy: 0.2719 - val_loss: 1.8236 - val_accuracy: 0.4208\n",
            "Epoch 3/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 1.8344 - accuracy: 0.4173 - val_loss: 1.5616 - val_accuracy: 0.5042\n",
            "Epoch 4/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 1.5567 - accuracy: 0.5082 - val_loss: 1.3654 - val_accuracy: 0.5938\n",
            "Epoch 5/40\n",
            "60/60 [==============================] - 10s 81ms/step - loss: 1.3971 - accuracy: 0.5540 - val_loss: 1.2261 - val_accuracy: 0.6333\n",
            "Epoch 6/40\n",
            "60/60 [==============================] - 10s 81ms/step - loss: 1.1859 - accuracy: 0.6398 - val_loss: 1.1129 - val_accuracy: 0.6604\n",
            "Epoch 7/40\n",
            "60/60 [==============================] - 10s 83ms/step - loss: 1.1234 - accuracy: 0.6663 - val_loss: 1.0315 - val_accuracy: 0.6833\n",
            "Epoch 8/40\n",
            "60/60 [==============================] - 10s 81ms/step - loss: 1.0635 - accuracy: 0.6669 - val_loss: 0.9580 - val_accuracy: 0.7104\n",
            "Epoch 9/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.9220 - accuracy: 0.7104 - val_loss: 0.9091 - val_accuracy: 0.7292\n",
            "Epoch 10/40\n",
            "60/60 [==============================] - 10s 83ms/step - loss: 0.9259 - accuracy: 0.6962 - val_loss: 0.8593 - val_accuracy: 0.7354\n",
            "Epoch 11/40\n",
            "60/60 [==============================] - 10s 83ms/step - loss: 0.8693 - accuracy: 0.7412 - val_loss: 0.8173 - val_accuracy: 0.7479\n",
            "Epoch 12/40\n",
            "60/60 [==============================] - 10s 83ms/step - loss: 0.7856 - accuracy: 0.7624 - val_loss: 0.7848 - val_accuracy: 0.7604\n",
            "Epoch 13/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.7784 - accuracy: 0.7438 - val_loss: 0.7538 - val_accuracy: 0.7667\n",
            "Epoch 14/40\n",
            "60/60 [==============================] - 10s 81ms/step - loss: 0.6975 - accuracy: 0.7784 - val_loss: 0.7319 - val_accuracy: 0.7688\n",
            "Epoch 15/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.7022 - accuracy: 0.7762 - val_loss: 0.7062 - val_accuracy: 0.7792\n",
            "Epoch 16/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.7053 - accuracy: 0.7737 - val_loss: 0.6900 - val_accuracy: 0.7854\n",
            "Epoch 17/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.6172 - accuracy: 0.8079 - val_loss: 0.6730 - val_accuracy: 0.7896\n",
            "Epoch 18/40\n",
            "60/60 [==============================] - 10s 81ms/step - loss: 0.6127 - accuracy: 0.8026 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 19/40\n",
            "60/60 [==============================] - 10s 81ms/step - loss: 0.6110 - accuracy: 0.7987 - val_loss: 0.6377 - val_accuracy: 0.8062\n",
            "Epoch 20/40\n",
            "60/60 [==============================] - 10s 81ms/step - loss: 0.5700 - accuracy: 0.8257 - val_loss: 0.6298 - val_accuracy: 0.8062\n",
            "Epoch 21/40\n",
            "60/60 [==============================] - 10s 81ms/step - loss: 0.5610 - accuracy: 0.8223 - val_loss: 0.6184 - val_accuracy: 0.8000\n",
            "Epoch 22/40\n",
            "60/60 [==============================] - 10s 84ms/step - loss: 0.5587 - accuracy: 0.8174 - val_loss: 0.6026 - val_accuracy: 0.8042\n",
            "Epoch 23/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.5098 - accuracy: 0.8511 - val_loss: 0.5929 - val_accuracy: 0.8146\n",
            "Epoch 24/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.5387 - accuracy: 0.8231 - val_loss: 0.5831 - val_accuracy: 0.8167\n",
            "Epoch 25/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.5107 - accuracy: 0.8427 - val_loss: 0.5767 - val_accuracy: 0.8125\n",
            "Epoch 26/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.5001 - accuracy: 0.8318 - val_loss: 0.5690 - val_accuracy: 0.8250\n",
            "Epoch 27/40\n",
            "60/60 [==============================] - 10s 84ms/step - loss: 0.4988 - accuracy: 0.8321 - val_loss: 0.5593 - val_accuracy: 0.8188\n",
            "Epoch 28/40\n",
            "60/60 [==============================] - 10s 83ms/step - loss: 0.4790 - accuracy: 0.8497 - val_loss: 0.5534 - val_accuracy: 0.8167\n",
            "Epoch 29/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.4871 - accuracy: 0.8378 - val_loss: 0.5450 - val_accuracy: 0.8250\n",
            "Epoch 30/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.4724 - accuracy: 0.8492 - val_loss: 0.5409 - val_accuracy: 0.8188\n",
            "Epoch 31/40\n",
            "60/60 [==============================] - 10s 82ms/step - loss: 0.4472 - accuracy: 0.8656 - val_loss: 0.5365 - val_accuracy: 0.8292\n",
            "Epoch 32/40\n",
            "60/60 [==============================] - 10s 85ms/step - loss: 0.4705 - accuracy: 0.8415 - val_loss: 0.5306 - val_accuracy: 0.8188\n",
            "Epoch 33/40\n",
            "60/60 [==============================] - 10s 83ms/step - loss: 0.4688 - accuracy: 0.8392 - val_loss: 0.5292 - val_accuracy: 0.8229\n",
            "Epoch 34/40\n",
            "60/60 [==============================] - 10s 83ms/step - loss: 0.4262 - accuracy: 0.8593 - val_loss: 0.5192 - val_accuracy: 0.8271\n",
            "Epoch 35/40\n",
            "60/60 [==============================] - 10s 84ms/step - loss: 0.4361 - accuracy: 0.8617 - val_loss: 0.5163 - val_accuracy: 0.8333\n",
            "Epoch 36/40\n",
            "60/60 [==============================] - 10s 84ms/step - loss: 0.4224 - accuracy: 0.8716 - val_loss: 0.5137 - val_accuracy: 0.8354\n",
            "Epoch 37/40\n",
            "60/60 [==============================] - 10s 83ms/step - loss: 0.4197 - accuracy: 0.8633 - val_loss: 0.5065 - val_accuracy: 0.8292\n",
            "Epoch 38/40\n",
            "60/60 [==============================] - 10s 84ms/step - loss: 0.4285 - accuracy: 0.8457 - val_loss: 0.5014 - val_accuracy: 0.8313\n",
            "Epoch 39/40\n",
            "60/60 [==============================] - 10s 85ms/step - loss: 0.4255 - accuracy: 0.8623 - val_loss: 0.4990 - val_accuracy: 0.8396\n",
            "Epoch 40/40\n",
            "60/60 [==============================] - 10s 84ms/step - loss: 0.4115 - accuracy: 0.8659 - val_loss: 0.4978 - val_accuracy: 0.8333\n",
            "15/15 [==============================] - 2s 71ms/step - loss: 0.4978 - accuracy: 0.8333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49775028228759766, 0.8333333134651184]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3l33gS0Rg-Q",
        "outputId": "6d306ae5-0e3f-4bb2-d328-88ccc195518e"
      },
      "source": [
        "#Fine Tuning. Le modèle est recompilé avec un taux d'apprentissage plus bas, et ses couches supérieures deviennent modifiables. Cela nous fait gagner\n",
        "#quelque pourcentages de précision de plus\n",
        "model = compile_for_fine_tuning(model, base_model, base_learning_rate).unlock(layer)\n",
        "model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)\n",
        "model.evaluate(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "60/60 [==============================] - 19s 124ms/step - loss: 0.7941 - accuracy: 0.7496 - val_loss: 0.4955 - val_accuracy: 0.8229\n",
            "Epoch 2/40\n",
            "60/60 [==============================] - 12s 107ms/step - loss: 0.6768 - accuracy: 0.7773 - val_loss: 0.4901 - val_accuracy: 0.8292\n",
            "Epoch 3/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.6295 - accuracy: 0.8008 - val_loss: 0.4866 - val_accuracy: 0.8313\n",
            "Epoch 4/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.5305 - accuracy: 0.8296 - val_loss: 0.4758 - val_accuracy: 0.8333\n",
            "Epoch 5/40\n",
            "60/60 [==============================] - 11s 106ms/step - loss: 0.5035 - accuracy: 0.8274 - val_loss: 0.4660 - val_accuracy: 0.8417\n",
            "Epoch 6/40\n",
            "60/60 [==============================] - 11s 105ms/step - loss: 0.4551 - accuracy: 0.8460 - val_loss: 0.4645 - val_accuracy: 0.8417\n",
            "Epoch 7/40\n",
            "60/60 [==============================] - 11s 108ms/step - loss: 0.4349 - accuracy: 0.8591 - val_loss: 0.4581 - val_accuracy: 0.8417\n",
            "Epoch 8/40\n",
            "60/60 [==============================] - 11s 106ms/step - loss: 0.4346 - accuracy: 0.8581 - val_loss: 0.4490 - val_accuracy: 0.8458\n",
            "Epoch 9/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.3782 - accuracy: 0.8763 - val_loss: 0.4451 - val_accuracy: 0.8417\n",
            "Epoch 10/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.3286 - accuracy: 0.8983 - val_loss: 0.4305 - val_accuracy: 0.8479\n",
            "Epoch 11/40\n",
            "60/60 [==============================] - 11s 108ms/step - loss: 0.3967 - accuracy: 0.8708 - val_loss: 0.4276 - val_accuracy: 0.8479\n",
            "Epoch 12/40\n",
            "60/60 [==============================] - 12s 108ms/step - loss: 0.3235 - accuracy: 0.8964 - val_loss: 0.4257 - val_accuracy: 0.8521\n",
            "Epoch 13/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.3085 - accuracy: 0.8960 - val_loss: 0.4186 - val_accuracy: 0.8521\n",
            "Epoch 14/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.2982 - accuracy: 0.8942 - val_loss: 0.4075 - val_accuracy: 0.8542\n",
            "Epoch 15/40\n",
            "60/60 [==============================] - 12s 109ms/step - loss: 0.2879 - accuracy: 0.9063 - val_loss: 0.3966 - val_accuracy: 0.8604\n",
            "Epoch 16/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.2719 - accuracy: 0.9202 - val_loss: 0.3961 - val_accuracy: 0.8583\n",
            "Epoch 17/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.2614 - accuracy: 0.9248 - val_loss: 0.3957 - val_accuracy: 0.8646\n",
            "Epoch 18/40\n",
            "60/60 [==============================] - 11s 106ms/step - loss: 0.2692 - accuracy: 0.9073 - val_loss: 0.3931 - val_accuracy: 0.8625\n",
            "Epoch 19/40\n",
            "60/60 [==============================] - 11s 108ms/step - loss: 0.2420 - accuracy: 0.9368 - val_loss: 0.3859 - val_accuracy: 0.8646\n",
            "Epoch 20/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.2516 - accuracy: 0.9169 - val_loss: 0.3763 - val_accuracy: 0.8729\n",
            "Epoch 21/40\n",
            "60/60 [==============================] - 11s 106ms/step - loss: 0.2023 - accuracy: 0.9469 - val_loss: 0.3763 - val_accuracy: 0.8687\n",
            "Epoch 22/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.2152 - accuracy: 0.9369 - val_loss: 0.3687 - val_accuracy: 0.8708\n",
            "Epoch 23/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.1843 - accuracy: 0.9449 - val_loss: 0.3702 - val_accuracy: 0.8687\n",
            "Epoch 24/40\n",
            "60/60 [==============================] - 12s 108ms/step - loss: 0.1850 - accuracy: 0.9458 - val_loss: 0.3674 - val_accuracy: 0.8687\n",
            "Epoch 25/40\n",
            "60/60 [==============================] - 11s 108ms/step - loss: 0.2039 - accuracy: 0.9389 - val_loss: 0.3710 - val_accuracy: 0.8646\n",
            "Epoch 26/40\n",
            "60/60 [==============================] - 12s 107ms/step - loss: 0.1846 - accuracy: 0.9473 - val_loss: 0.3757 - val_accuracy: 0.8583\n",
            "Epoch 27/40\n",
            "60/60 [==============================] - 12s 109ms/step - loss: 0.1554 - accuracy: 0.9567 - val_loss: 0.3677 - val_accuracy: 0.8625\n",
            "Epoch 28/40\n",
            "60/60 [==============================] - 12s 107ms/step - loss: 0.1499 - accuracy: 0.9540 - val_loss: 0.3659 - val_accuracy: 0.8583\n",
            "Epoch 29/40\n",
            "60/60 [==============================] - 11s 106ms/step - loss: 0.1563 - accuracy: 0.9557 - val_loss: 0.3641 - val_accuracy: 0.8583\n",
            "Epoch 30/40\n",
            "60/60 [==============================] - 11s 106ms/step - loss: 0.1748 - accuracy: 0.9484 - val_loss: 0.3607 - val_accuracy: 0.8625\n",
            "Epoch 31/40\n",
            "60/60 [==============================] - 11s 106ms/step - loss: 0.1627 - accuracy: 0.9505 - val_loss: 0.3570 - val_accuracy: 0.8604\n",
            "Epoch 32/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.1308 - accuracy: 0.9691 - val_loss: 0.3617 - val_accuracy: 0.8583\n",
            "Epoch 33/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.1377 - accuracy: 0.9642 - val_loss: 0.3594 - val_accuracy: 0.8604\n",
            "Epoch 34/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.1240 - accuracy: 0.9671 - val_loss: 0.3561 - val_accuracy: 0.8625\n",
            "Epoch 35/40\n",
            "60/60 [==============================] - 12s 108ms/step - loss: 0.1319 - accuracy: 0.9656 - val_loss: 0.3593 - val_accuracy: 0.8562\n",
            "Epoch 36/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.1217 - accuracy: 0.9696 - val_loss: 0.3549 - val_accuracy: 0.8583\n",
            "Epoch 37/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.1097 - accuracy: 0.9689 - val_loss: 0.3529 - val_accuracy: 0.8604\n",
            "Epoch 38/40\n",
            "60/60 [==============================] - 11s 107ms/step - loss: 0.1278 - accuracy: 0.9659 - val_loss: 0.3514 - val_accuracy: 0.8646\n",
            "Epoch 39/40\n",
            "60/60 [==============================] - 12s 109ms/step - loss: 0.1059 - accuracy: 0.9743 - val_loss: 0.3507 - val_accuracy: 0.8583\n",
            "Epoch 40/40\n",
            "60/60 [==============================] - 11s 106ms/step - loss: 0.1077 - accuracy: 0.9729 - val_loss: 0.3479 - val_accuracy: 0.8583\n",
            "15/15 [==============================] - 2s 74ms/step - loss: 0.3479 - accuracy: 0.8583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34788912534713745, 0.8583333492279053]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qc5CVHiRiPX",
        "outputId": "436c3ef5-d794-41a2-ff5f-462721849cec"
      },
      "source": [
        "#Sauvegarde du modèle dans un fichier. Il peut être importé plus tard, pour nous éviter de reentraîner un modèle à chaque fois.\n",
        "model.save(save_directory)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./Caches/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u5nyVO2aN8v"
      },
      "source": [
        "**Prediction Time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_18DQZpabAf",
        "outputId": "056cad2d-c774-4169-9ac2-d236adbc78d5"
      },
      "source": [
        "model = tf.keras.models.load_model(save_directory)\n",
        "\n",
        "for path in sorted(glob(\"./Image_Test/*\")):\n",
        "    img = tf.keras.preprocessing.image.load_img(path, target_size=(image_height, image_width, 3))\n",
        "\n",
        "    #Transforme l'image en array, où chaque pixel est une liste, avec 3 valeurs RBG\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "    #Prédit la ressemblance de l'image avec chaqu'une des classes qu'elle connaît\n",
        "    predictions = model.predict(img_array)\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "\n",
        "    print(f\"L'Image {path} appartient sûrement aux {class_names[np.argmax(score)]} avec {round(np.max(score)*100, 2)}% de sûreté\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L'Image ./Image_Test/Colin_test2.png appartient sûrement aux /Persian avec 99.68% de sûreté\n",
            "L'Image ./Image_Test/Colin_test3.png appartient sûrement aux /Persian avec 98.06% de sûreté\n",
            "L'Image ./Image_Test/birman1.jpg appartient sûrement aux /Birman avec 96.74% de sûreté\n",
            "L'Image ./Image_Test/birman2.jpg appartient sûrement aux /Ragdoll avec 87.27% de sûreté\n",
            "L'Image ./Image_Test/birman3.jpg appartient sûrement aux /Ragdoll avec 83.92% de sûreté\n",
            "L'Image ./Image_Test/birman4.jpg appartient sûrement aux /Ragdoll avec 58.67% de sûreté\n",
            "L'Image ./Image_Test/birman5.jpg appartient sûrement aux /Birman avec 85.97% de sûreté\n",
            "L'Image ./Image_Test/colin.png appartient sûrement aux /Persian avec 48.71% de sûreté\n",
            "L'Image ./Image_Test/demon.png appartient sûrement aux /Sphynx avec 99.39% de sûreté\n",
            "L'Image ./Image_Test/edgar.jpg appartient sûrement aux /Russian_Blue avec 99.64% de sûreté\n",
            "L'Image ./Image_Test/kael.png appartient sûrement aux /Persian avec 99.91% de sûreté\n",
            "L'Image ./Image_Test/kael2.png appartient sûrement aux /Bengal avec 55.26% de sûreté\n",
            "L'Image ./Image_Test/maine_coon.jpg appartient sûrement aux /Maine_Coon avec 99.34% de sûreté\n",
            "L'Image ./Image_Test/max.png appartient sûrement aux /Bombay avec 55.33% de sûreté\n",
            "L'Image ./Image_Test/ragdoll.png appartient sûrement aux /Birman avec 53.12% de sûreté\n",
            "L'Image ./Image_Test/ragdoll2.jpg appartient sûrement aux /Ragdoll avec 93.8% de sûreté\n",
            "L'Image ./Image_Test/ragdoll3.jpg appartient sûrement aux /Ragdoll avec 58.79% de sûreté\n",
            "L'Image ./Image_Test/ragdoll4.jpg appartient sûrement aux /Ragdoll avec 99.47% de sûreté\n",
            "L'Image ./Image_Test/siamese.jpg appartient sûrement aux /Siamese avec 94.87% de sûreté\n",
            "L'Image ./Image_Test/siamese2.jpg appartient sûrement aux /Siamese avec 90.82% de sûreté\n",
            "L'Image ./Image_Test/siamese3.jpg appartient sûrement aux /Siamese avec 96.22% de sûreté\n",
            "L'Image ./Image_Test/siamese4.jpg appartient sûrement aux /Siamese avec 99.92% de sûreté\n",
            "L'Image ./Image_Test/sleepy.jpg appartient sûrement aux /Bombay avec 75.69% de sûreté\n",
            "L'Image ./Image_Test/sleepy2.jpg appartient sûrement aux /Maine_Coon avec 93.99% de sûreté\n",
            "L'Image ./Image_Test/sleepy3.jpg appartient sûrement aux /Bengal avec 29.93% de sûreté\n",
            "L'Image ./Image_Test/sylv1.jpg appartient sûrement aux /Persian avec 97.1% de sûreté\n",
            "L'Image ./Image_Test/sylv2.jpg appartient sûrement aux /Persian avec 75.76% de sûreté\n",
            "L'Image ./Image_Test/sylv3.jpg appartient sûrement aux /Persian avec 86.71% de sûreté\n",
            "L'Image ./Image_Test/test1.jpg appartient sûrement aux /British_Shorthair avec 29.51% de sûreté\n",
            "L'Image ./Image_Test/test10.png appartient sûrement aux /Persian avec 53.76% de sûreté\n",
            "L'Image ./Image_Test/test2.jpg appartient sûrement aux /Bombay avec 59.2% de sûreté\n",
            "L'Image ./Image_Test/test3.jpg appartient sûrement aux /Bombay avec 81.53% de sûreté\n",
            "L'Image ./Image_Test/test4.jpg appartient sûrement aux /Bombay avec 99.62% de sûreté\n",
            "L'Image ./Image_Test/test5.jpg appartient sûrement aux /Bombay avec 99.93% de sûreté\n",
            "L'Image ./Image_Test/test6.jpg appartient sûrement aux /Maine_Coon avec 44.61% de sûreté\n",
            "L'Image ./Image_Test/test7.jpg appartient sûrement aux /Persian avec 46.41% de sûreté\n",
            "L'Image ./Image_Test/test8.jpg appartient sûrement aux /Maine_Coon avec 98.93% de sûreté\n",
            "L'Image ./Image_Test/test9.jpg appartient sûrement aux /Ragdoll avec 25.93% de sûreté\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}